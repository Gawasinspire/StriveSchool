{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "4.3 Pytorch MNIST - Exercise.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBsAIDUCblTx"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "    <h2 align=\"center\">Deep Learning Fundamentals</h2>\n",
        "    <h2 align=\"center\" style=\"color:#01ff84\">Multiclass Classification: MNIST</h2>\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9mYyoIDblUB"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:36.081105Z",
          "start_time": "2021-05-26T22:26:35.040138Z"
        },
        "id": "chdioGGPblUE"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vB5keISblUJ"
      },
      "source": [
        "## Auxliary plotting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:37.473177Z",
          "start_time": "2021-05-26T22:26:37.465910Z"
        },
        "id": "Z0Ioi9iyblUL"
      },
      "source": [
        "# https://discuss.pytorch.org/t/view-classify-in-module-helper/30279/6\n",
        "\n",
        "def view_classify(img, ps):\n",
        "\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOHz4OgJblUO"
      },
      "source": [
        "# Load MNIST Dataset\n",
        "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:38.402766Z",
          "start_time": "2021-05-26T22:26:38.298968Z"
        },
        "id": "PBowuGI1blUQ"
      },
      "source": [
        "# Define a transform to normalize the data (Preprocessing)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:38.632988Z",
          "start_time": "2021-05-26T22:26:38.477558Z"
        },
        "id": "IBF5S57zblUS"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlYu3mt2blUU"
      },
      "source": [
        "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:39.407000Z",
          "start_time": "2021-05-26T22:26:39.265256Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "1kd9fw7wblUY",
        "outputId": "3587f98b-a5a8-4725-dbc3-d1a6100aa439"
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHwCAYAAAC7cCafAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcMElEQVR4nO3de8xldXkv8O8DtHJKKgptNcbTDFIV0osKtOUSkYv1aBsVKiP+IZAGTO2hx2L1tCdeeqatpDZpigpe2tqWBtMzbcZI0yNVT7gIiNU41HKMF0AYOKYqAjLItc7wO3/sNTod33cue+159/v+9ueT7Kx3r7We/XtYLPi+a7/rUq21AAD9OGDeDQAAsyXcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzB827gf2hqu5M8uQkW+bcCgBMa12SB1trR+xrYZfhnkmwHza8AGCh9Pq1/JZ5NwAAM7BlmqK5hntVPbOq/qqq/q2qHq+qLVX1rqp66jz7AoC1bG5fy1fVkUluSvITSf4hyZeT/EKS30ry0qo6qbV237z6A4C1ap5H7u/LJNjf0Fo7o7X2P1prpyW5JMlzk1w8x94AYM2q1trKDzo5ar89k78lHNlae2KnZT+a5OtJKslPtNYenuLzNyc5ZjbdAsDc3NxaO3Zfi+b1tfypw/QTOwd7krTWvlNVn0rykiTHJ7l6uQ8ZQnwpR82kSwBYg+b1tfxzh+mtyyy/bZg+ZwV6AYCuzOvI/dBhunWZ5TvmP2V3H7LcVxW+lgdgkfV6nTsALKx5hfuOI/NDl1m+Y/4DK9ALAHRlXuH+lWG63N/Unz1Ml/ubPACwjHmF+7XD9CVV9R96GC6FOynJI0n+eaUbA4C1bi7h3lr7apJPZPLEmwt3Wfz7SQ5JcsU017gDwKKb51Ph/msmt599T1WdnuRLSX4xk2vgb03y1jn2BgBr1tzOlh+O3o9Lcnkmof6mJEcmeXeS491XHgCmM9fnubfW/l+SX5tnDwDQG9e5A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdGZu4V5VW6qqLfP6xrz6AoC17qA5j781ybuWmP/QSjcCAL2Yd7g/0FrbMOceAKAr/uYOAJ2Z95H7k6rqtUl+MsnDSW5Jcn1rbft82wKAtWve4f70JFfsMu/Oqvq11ton91RcVZuXWXTU6M4AYI2a59fyf53k9EwC/pAkP5vkz5KsS/JPVfW8+bUGAGtXtdbm3cN/UFV/kuRNSa5srZ055WdsTnLMTBsDgJV3c2vt2H0tWo0n1H1gmJ481y4AYI1ajeH+rWF6yFy7AIA1ajWG+/HD9I65dgEAa9Rcwr2qjq6qHzgyr6p1SS4b3n5oJXsCgF7M61K4s5O8qaquT3JXku8kOTLJryQ5OMlVSf5kTr0BwJo2r3C/Nslzk7wgyUmZ/H39gSQ3ZnLd+xVttZ3GDwBrxFzCfbhBzR5vUgMA7LvVeEIdADCCcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOjMXJ7nDnzfueeeO3XtK1/5ylFjn3nmmaPq56mqpq696667Ro195JFHTl27ffv2UWPD3nDkDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BmPfIUkhx566NS173vf+0aNffbZZ09d+9hjj40a+84775y69s///M9HjT3W6aefPnXti1/84lFjH3DA9MdFYx/5evjhh09de999940am7XDkTsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdMbz3CHJVVddNXXtCSecMGrsTZs2TV27YcOGUWN/8YtfHFU/T9/97nenrh37PPcjjjhi6toLL7xw1Njr16+fuva9733vqLEvvvjiUfWsHEfuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnfHIV7rwt3/7t6Pqjz322Klrt27dOmrs8847b+raRx99dNTYY6xbt25U/caNG0fVf+5znxtVP8ZnPvOZqWsPPfTQUWM//vjjU9d+6lOfGjU2a4cjdwDozEzCvarOqqpLq+qGqnqwqlpVfWgPNSdW1VVVdX9VPVpVt1TVRVV14Cx6AoBFNauv5d+W5HlJHkrytSRH7W7lqnplkg8neSzJ3yW5P8nLk1yS5KQk62fUFwAsnFl9Lf/GJM9J8uQkv7G7FavqyUn+Isn2JKe01s5vrf33JM9P8ukkZ1XVa2bUFwAsnJmEe2vt2tbaba21thern5Xkx5NsbK1974yY1tpjmXwDkOzhFwQAYHnzOKHutGH6sSWWXZ/kkSQnVtWTVq4lAOjHPC6Fe+4wvXXXBa21bVV1Z5KfTvKsJF/a3QdV1eZlFu32b/4A0LN5HLnvuMhzuYuDd8x/ygr0AgDdWdM3sWmtLXnnkeGI/pgVbgcAVoV5HLnvODJf7jZNO+Y/sAK9AEB35hHuXxmmz9l1QVUdlOSIJNuS3LGSTQFAL+YR7tcM05cusezkJD+S5KbW2vQ3UAaABTaPcN+U5N4kr6mq43bMrKqDk7xjePv+OfQFAF2YyQl1VXVGkjOGt08fpidU1eXDz/e21t6cJK21B6vqdZmE/HVVtTGT28++IpPL5DZlcktaAGAKszpb/vlJdn1u5bOGV5LcleTNOxa01q6sqhcleWuSVyU5OMntSX47yXv28k53AMASZhLurbUNSTbsY82nkvzyLMaHF7zgBaPqxzwX/bTTTtvzSvtp7HnasmXLqPqPfvSjo+pf+MIXjqofY+wz2cf47Gc/O3XtddddN7tGWNU8zx0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzs3qeO6xpt9xyy9S1//Iv/zLDTlbWj/3Yj01d+8d//Mejxj733HNH1R944IGj6ufl5ptvHlX/y7/sSdnsmSN3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiM57lDkpNOOmnq2r/5m78ZNfbDDz88de35558/auwxDjhg3LHB1VdfPar+sMMOm7r2uOOOGzX2GFdeeeWo+jH7C4vDkTsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnPPKVLmzdunVuY59zzjmj6sc8wvOhhx4aNfY73vGOqWsvueSSUWOPdc0118xt7BtuuGHq2jHbHPaWI3cA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IznudOF448/flT9eeedN3XtYYcdNmrsSy+9dOrabdu2jRp7ns4+++xR9SeccMKMOtl3L37xi+c2NuwNR+4A0JmZhHtVnVVVl1bVDVX1YFW1qvrQMuuuG5Yv99o4i54AYFHN6mv5tyV5XpKHknwtyVF7UfOvSa5cYv4XZtQTACykWYX7GzMJ9duTvCjJtXtR8/nW2oYZjQ8ADGYS7q2174V5Vc3iIwGAKc3zbPlnVNWvJzk8yX1JPt1au2VfPqCqNi+zaG/+LAAAXZpnuP/S8PqeqrouyXmttbvn0hEAdGAe4f5Ikj/M5GS6O4Z5P5dkQ5JTk1xdVc9vrT28pw9qrR271PzhiP6YmXQLAGvMil/n3lq7p7X2e621m1trDwyv65O8JMlnkvxUkgtWui8A6MWquYlNa21bkg8Ob0+eZy8AsJatmnAffGuYHjLXLgBgDVtt4b7jBuF37HYtAGBZKx7uVXVMVf3AuFV1eiY3w0mSJW9dCwDs2UzOlq+qM5KcMbx9+jA9oaouH36+t7X25uHnP03y7Kq6KZO72iWTs+VPG35+e2vtpln0BQCLaFaXwj0/ya7PzHzW8EqSu5LsCPcrkpyZ5OeTvCzJDyX5ZpK/T3JZa+2GGfUEAAupWmvz7mHmXOcOq99tt902qv7II4+cuvYjH/nIqLHXr18/de0TTzwxamwWzs3L3dNld1bbCXUAwEjCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6M6vnuQML5oILLhhV/8xnPnNU/YMPPjh17ete97pRY3tsK6udI3cA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IznucMCO/roo6euveyyy0aN/cM//MOj6m+88capa++///5RY8Nq58gdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgMx75Cgvsj/7oj6auHfvI1m9/+9uj6i+88MJR9dAzR+4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnPc4c17PWvf/2o+pe//OVT17bWRo392te+dlT9rbfeOqoeejb6yL2qDq+qC6rqI1V1e1U9WlVbq+rGqjq/qpYco6pOrKqrqur+oeaWqrqoqg4c2xMALLJZHLmvT/L+JF9Pcm2Su5M8LcmvJvlgkpdV1fq206/5VfXKJB9O8liSv0tyf5KXJ7kkyUnDZwIAU5hFuN+a5BVJPtpae2LHzKp6S5LPJnlVJkH/4WH+k5P8RZLtSU5prX1umP/2JNckOauqXtNa2ziD3gBg4Yz+Wr61dk1r7R93DvZh/jeSfGB4e8pOi85K8uNJNu4I9mH9x5K8bXj7G2P7AoBFtb/Plv/uMN2207zThunHllj/+iSPJDmxqp60PxsDgF7tt7Plq+qgJOcOb3cO8ucO0x841bW1tq2q7kzy00meleRLexhj8zKLjtq3bgGgH/vzyP2dSX4myVWttY/vNP/QYbp1mbod85+yvxoDgJ7tlyP3qnpDkjcl+XKSc/bHGEnSWjt2mfE3Jzlmf40LAKvZzI/cq+o3k7w7yReTnNpau3+XVXYcmR+ape2Y/8CsewOARTDTcK+qi5JcmuQLmQT7N5ZY7SvD9DlL1B+U5IhMTsC7Y5a9AcCimFm4V9XvZnITms9nEuz3LLPqNcP0pUssOznJjyS5qbX2+Kx6A4BFMpNwH25A884km5Oc3lq7dzerb0pyb5LXVNVxO33GwUneMbx9/yz6AoBFNPqEuqo6L8kfZHLHuRuSvKGqdl1tS2vt8iRprT1YVa/LJOSvq6qNmdx+9hWZXCa3KZNb0gIAU5jF2fJHDNMDk1y0zDqfTHL5jjettSur6kVJ3prJ7WkPTnJ7kt9O8p429nFTALDAqsccdSkca8lBB03/O/aWLVtGjf20pz1t6tpLLrlk1Ni/8zu/M6oeFsTNy132vTv7+/azAMAKE+4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdmf5B0sBMvOUtb5m69hnPeMaosb/5zW9OXet57LB6OXIHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojEe+wpy99a1vnbp2+/bto8a+7LLLRtUDq5MjdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojOe5w0hHH330qPqqmrr2q1/96qixL7744lH1wOrkyB0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzHvkKI7361a8eVX/QQdP/Z7hp06ZRYwN9cuQOAJ0ZHe5VdXhVXVBVH6mq26vq0araWlU3VtX5VXXALuuvq6q2m9fGsT0BwCKbxdfy65O8P8nXk1yb5O4kT0vyq0k+mORlVbW+tdZ2qfvXJFcu8XlfmEFPALCwZhHutyZ5RZKPttae2DGzqt6S5LNJXpVJ0H94l7rPt9Y2zGB8AGAno7+Wb61d01r7x52DfZj/jSQfGN6eMnYcAGDv7O+z5b87TLctsewZVfXrSQ5Pcl+ST7fWbtnP/QBA9/ZbuFfVQUnOHd5+bIlVfml47VxzXZLzWmt37+UYm5dZdNRetgkA3dmfl8K9M8nPJLmqtfbxneY/kuQPkxyb5KnD60WZnIx3SpKrq+qQ/dgXAHRtvxy5V9UbkrwpyZeTnLPzstbaPUl+b5eS66vqJUluTPKLSS5I8u49jdNaO3aZ8TcnOWbfOweAtW/mR+5V9ZuZBPMXk5zaWrt/b+paa9syuXQuSU6edV8AsChmGu5VdVGSSzO5Vv3U4Yz5ffGtYepreQCY0szCvap+N8klST6fSbDfM8XHHD9M75hVXwCwaGYS7lX19kxOoNuc5PTW2r27WfeYXW9JO8w/Pckbh7cfmkVfALCIRp9QV1XnJfmDJNuT3JDkDVW162pbWmuXDz//aZJnV9VNSb42zPu5JKcNP7+9tXbT2L4AYFHN4mz5I4bpgUkuWmadTya5fPj5iiRnJvn5JC9L8kNJvpnk75Nc1lq7YQY9AcDCGh3uw/3hN+zD+n+Z5C/Hjgu92L59+9S1F1988Qw7AXrhee4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdqdbavHuYuaranOSYefcBACPd3Fo7dl+LHLkDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0ptdwXzfvBgBgBtZNU3TQjJtYLR4cpluWWX7UMP3y/m+lG7bZdGy36dhu+842m85q3m7r8v082yfVWpttK2tAVW1OktbasfPuZa2wzaZju03Hdtt3ttl0et1uvX4tDwALS7gDQGeEOwB0RrgDQGeEOwB0ZiHPlgeAnjlyB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOLFS4V9Uzq+qvqurfqurxqtpSVe+qqqfOu7fVathGbZnXN+bd37xU1VlVdWlV3VBVDw7b40N7qDmxqq6qqvur6tGquqWqLqqqA1eq73nbl+1WVet2s++1qtq40v3PQ1UdXlUXVNVHqur2Yd/ZWlU3VtX5VbXk/8cXfX/b1+3W2/7W6/Pcf0BVHZnkpiQ/keQfMnl27y8k+a0kL62qk1pr982xxdVsa5J3LTH/oZVuZBV5W5LnZbINvpbvPxN6SVX1yiQfTvJYkr9Lcn+Slye5JMlJSdbvz2ZXkX3aboN/TXLlEvO/MMO+VrP1Sd6f5OtJrk1yd5KnJfnVJB9M8rKqWt92uiOZ/S3JFNtt0Mf+1lpbiFeSjydpSf7bLvP/dJj/gXn3uBpfSbYk2TLvPlbbK8mpSZ6dpJKcMuxDH1pm3ScnuSfJ40mO22n+wZn8wtmSvGbe/0yrcLutG5ZfPu++57zNTsskmA/YZf7TMwmsluRVO823v0233bra3xbia/nhqP0lmQTVe3dZ/D+TPJzknKo6ZIVbY41qrV3bWrutDf9X2IOzkvx4ko2ttc/t9BmPZXIkmyS/sR/aXHX2cbuRpLV2TWvtH1trT+wy/xtJPjC8PWWnRfa3TLXdurIoX8ufOkw/scS/6O9U1acyCf/jk1y90s2tAU+qqtcm+clMfhG6Jcn1rbXt821rzThtmH5siWXXJ3kkyYlV9aTW2uMr19aa8Yyq+vUkhye5L8mnW2u3zLmn1eK7w3TbTvPsb3u21HbboYv9bVHC/bnD9NZllt+WSbg/J8J9KU9PcsUu8+6sql9rrX1yHg2tMcvuf621bVV1Z5KfTvKsJF9aycbWiF8aXt9TVdclOa+1dvdcOloFquqgJOcOb3cOcvvbbuxmu+3Qxf62EF/LJzl0mG5dZvmO+U9ZgV7Wmr9OcnomAX9Ikp9N8meZ/H3qn6rqefNrbc2w/03nkSR/mOTYJE8dXi/K5OSoU5JcveB/Sntnkp9JclVr7eM7zbe/7d5y262r/W1Rwp0ptdZ+f/jb1Tdba4+01r7QWnt9Jici/qckG+bbIb1qrd3TWvu91trNrbUHhtf1mXzL9pkkP5Xkgvl2OR9V9YYkb8rkqp9z5tzOmrG77dbb/rYo4b7jN9VDl1m+Y/4DK9BLL3ackHLyXLtYG+x/M9Ra25bJpUzJAu5/VfWbSd6d5ItJTm2t3b/LKva3JezFdlvSWt3fFiXcvzJMn7PM8mcP0+X+Js8P+tYwXTNfU83Rsvvf8Pe/IzI5seeOlWxqjVvI/a+qLkpyaSbXXJ86nPm9K/vbLvZyu+3OmtvfFiXcrx2mL1nirkQ/mslNHR5J8s8r3dgadvwwXZj/QYxwzTB96RLLTk7yI0luWuAzl6excPtfVf1uJjeh+XwmAXXPMqva33ayD9ttd9bc/rYQ4d5a+2qST2RyEtiFuyz+/Ux+G7uitfbwCre2qlXV0UudQFJV65JcNrzd7S1XSZJsSnJvktdU1XE7ZlbVwUneMbx9/zwaW82q6pilbq1aVacneePwdiH2v6p6eyYngm1Ocnpr7d7drG5/G+zLduttf6tFuZfEEref/VKSX8zkGvhbk5zY3H72P6iqDZmcfHJ9kruSfCfJkUl+JZO7XV2V5MzW2r/Pq8d5qaozkpwxvH16kv+SyW/1Nwzz7m2tvXmX9TdlcjvQjZncDvQVmVy2tCnJqxfhxi77st2Gy4+encl/t18blv9cvn8d99tbazvCqltVdV6Sy5Nsz+Sr5aXOgt/SWrt8p5qF39/2dbt1t7/N+xZ5K/lK8p8zubTr60n+PZPAeleSp867t9X4yuQykP+VyZmlD2Ry44dvJfk/mVwnWvPucY7bZkMmt6pc7rVliZqTMvmF6NtJHk3yfzM5Ijhw3v88q3G7JTk/yf/O5M6SD2VyO9W7M7lX+gvn/c+yirZZS3Kd/W3cduttf1uYI3cAWBQL8Td3AFgkwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAz/x9K15mZpjG3vwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 251,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPvFFPWfblUf"
      },
      "source": [
        "## Building networks with PyTorch\n",
        "\n",
        "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
        "\n",
        "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
        "\n",
        "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
        "\n",
        "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
        "\n",
        "<img src=\"assets/activation.png\" width=700px>\n",
        "\n",
        "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:39.961531Z",
          "start_time": "2021-05-26T22:26:39.946776Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2j7gR4nblUi",
        "outputId": "24aea9ec-ca77-44bb-a12c-029513c561c0"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    # Defining the layers, 128, 64, 10 units each\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 10)\n",
        "        \n",
        "    # Forward pass through the network, returns the output logits\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
              "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iDi0_l6blUj"
      },
      "source": [
        "Why the input features are 784? Because the input images have size 28 pixels x 28 pixels for a total of 784 features. Since a Multilayer perceptron accepts only flatten inputs, we need to flatten a 28x28 grid into a 784 array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxIYk_0_blUk"
      },
      "source": [
        "### Sequential API\n",
        "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:41.213448Z",
          "start_time": "2021-05-26T22:26:41.205216Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njqI-yBxblUm",
        "outputId": "fd10d4a1-7ff2-40a6-ea74-65b3968a0e6a"
      },
      "source": [
        "# Hyperparameters for our network\n",
        "input_size   = 784\n",
        "hidden_sizes = [4, 4]\n",
        "output_size   = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.Softmax(dim=1))\n",
        "print(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=4, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=4, out_features=10, bias=True)\n",
            "  (5): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF0znn4mblUo"
      },
      "source": [
        "You can also pass in an `OrderedDict` to name the individual layers and operations. Note that a dictionary keys must be unique, so _each operation must have a different name_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:42.300216Z",
          "start_time": "2021-05-26T22:26:42.289009Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNPwB9PoblUo",
        "outputId": "257d8786-d118-451f-f193-aebcffeabab1"
      },
      "source": [
        "model = nn.Sequential(OrderedDict([\n",
        "          ('fc1',   nn.Linear(input_size, hidden_sizes[0])),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2',   nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
        "          ('softmax', nn.Softmax(dim=1))]))\n",
        "model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (output): Linear(in_features=4, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rx4SCNSblUq"
      },
      "source": [
        "### Initializing weights and biases\n",
        "\n",
        "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:42.972699Z",
          "start_time": "2021-05-26T22:26:42.963913Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP4FH_IublUr",
        "outputId": "108f7131-e8c4-48a5-e40f-037368a55525"
      },
      "source": [
        "print(model.fc1.weight)\n",
        "print(model.fc1.bias)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0116,  0.0184, -0.0048,  ..., -0.0095,  0.0056, -0.0269],\n",
            "        [-0.0114,  0.0094, -0.0284,  ...,  0.0098, -0.0118,  0.0039],\n",
            "        [-0.0340, -0.0223, -0.0178,  ...,  0.0327,  0.0216,  0.0220],\n",
            "        [-0.0238,  0.0209,  0.0100,  ...,  0.0319, -0.0103,  0.0199]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0062, -0.0010, -0.0092,  0.0078], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eMZmLzwblUr"
      },
      "source": [
        "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:43.889729Z",
          "start_time": "2021-05-26T22:26:43.883940Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIv-4dWWblUs",
        "outputId": "2d3d7ecd-bbce-4c9d-cc2e-cdbf06d691c0"
      },
      "source": [
        "# Set biases to all zeros\n",
        "model.fc1.bias.data.fill_(0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:44.084097Z",
          "start_time": "2021-05-26T22:26:44.076738Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8blDD33NblUt",
        "outputId": "acbd0cef-640d-49a8-d72d-b255e3729f5d"
      },
      "source": [
        "# sample from random normal with standard dev = 0.01\n",
        "model.fc1.weight.data.normal_(std=0.01)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0151,  0.0076, -0.0002,  ..., -0.0024, -0.0006, -0.0019],\n",
              "        [ 0.0005,  0.0024, -0.0101,  ...,  0.0040, -0.0061, -0.0100],\n",
              "        [-0.0072, -0.0167, -0.0167,  ..., -0.0087,  0.0097,  0.0083],\n",
              "        [-0.0085,  0.0112, -0.0043,  ...,  0.0006,  0.0108, -0.0128]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W95A7fgDblUu"
      },
      "source": [
        "### STEP 1: Forward pass\n",
        "\n",
        "Now that we have a network, let's see what happens when we pass in an image. This is called the forward pass. We're going to convert the image data into a tensor, then pass it through the operations defined by the network architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:44.506324Z",
          "start_time": "2021-05-26T22:26:44.491847Z"
        },
        "id": "m8YSoB6oblUv"
      },
      "source": [
        "# Grab some data \n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:44.596541Z",
          "start_time": "2021-05-26T22:26:44.594169Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQOHTOmxblUv",
        "outputId": "be212f44-fa5b-428c-a3d6-986f50bda22b"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:44.851894Z",
          "start_time": "2021-05-26T22:26:44.845888Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t3z_DkoblUx",
        "outputId": "04c16084-aa97-4837-bc7f-f8cc8c06d250"
      },
      "source": [
        "model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (output): Linear(in_features=4, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:46.121246Z",
          "start_time": "2021-05-26T22:26:46.112022Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFXXjDF2blUx",
        "outputId": "b0d57b32-e30f-447b-a216-014daecbe7c6"
      },
      "source": [
        "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "# or images.resize_(images.shape[0], 1, 784) to not automatically get batch size"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:46.519895Z",
          "start_time": "2021-05-26T22:26:46.514137Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiW-9oHjblUz",
        "outputId": "4a4ee27c-9f08-4941-c2c4-6b97c29889b0"
      },
      "source": [
        "img_idx = 0\n",
        "images[img_idx,:].shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:47.945952Z",
          "start_time": "2021-05-26T22:26:47.888846Z"
        },
        "id": "uVrzqcxjblU0"
      },
      "source": [
        "# Forward pass through the network\n",
        "img_idx = 0\n",
        "ps = model(images[img_idx,:])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:50.561845Z",
          "start_time": "2021-05-26T22:26:50.411449Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "HYqobAxYblU1",
        "outputId": "6fd81a9f-58dd-4357-bc33-3f4abae0c20f"
      },
      "source": [
        "img = images[img_idx]\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 349,
              "height": 195
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj4vyFfoblU2"
      },
      "source": [
        "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDtyoEtRblU3"
      },
      "source": [
        "# Training Neural Networks\n",
        "\n",
        "The network we built isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
        "\n",
        "<img src=\"assets/function_approx.png\" width=500px>\n",
        "\n",
        "At first the network is naive, it doesn't know the function mapping the inputs to the outputs. We train the network by showing it examples of real data, then adjusting the network parameters such that it approximates this function.\n",
        "\n",
        "To find these parameters, we need to know how poorly the network is predicting the real outputs. For this we calculate a **loss function** (also called the cost), a measure of our prediction error. For example, the mean squared loss is often used in regression and binary classification problems\n",
        "\n",
        "$$\n",
        "\\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
        "$$\n",
        "\n",
        "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels.\n",
        "\n",
        "By minimizing this loss with respect to the network parameters, we can find configurations where the loss is at a minimum and the network is able to predict the correct labels with high accuracy. We find this minimum using a process called **gradient descent**. The gradient is the slope of the loss function and points in the direction of fastest change. To get to the minimum in the least amount of time, we then want to follow the gradient (downwards). You can think of this like descending a mountain by following the steepest slope to the base.\n",
        "\n",
        "<img src='assets/gradient_descent.png' width=350px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1cU6J7kblU5"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "For single layer networks, gradient descent is simple to implement. However, it's more complicated for deeper, multilayer neural networks like the one we've built. Complicated enough that it took about 30 years before researchers figured out how to train multilayer networks, although it's straightforward once you learn about it. \n",
        "\n",
        "This is done through **backpropagation** which is really just an application of the chain rule from calculus. It's easiest to understand if we convert a two layer network into a graph representation.\n",
        "\n",
        "<img src='assets/w1_backprop_graph.png' width=400px>\n",
        "\n",
        "In the forward pass through the network, our data and operations go from right to left here. To train the weights with gradient descent, we propagate the gradient of the cost backwards through the network. Mathematically, this is really just calculating the gradient of the loss with respect to the weights using the chain rule.\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\ell}{\\partial w_1} = \\frac{\\partial l_1}{\\partial w_1} \\frac{\\partial s}{\\partial l_1} \\frac{\\partial l_2}{\\partial s} \\frac{\\partial \\ell}{\\partial l_2}\n",
        "$$\n",
        "\n",
        "We update our weights using this gradient with some learning rate $\\alpha$. \n",
        "\n",
        "$$\n",
        "w^\\prime = w - \\alpha \\frac{\\partial \\ell}{\\partial w}\n",
        "$$\n",
        "\n",
        "The learning rate is set such that the weight update steps are small enough that the iterative method settles in a minimum.\n",
        "\n",
        "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
        "\n",
        "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feTlPw4hblU6"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "Torch provides a module, `autograd`, for automatically calculating the gradient of tensors. It does this by keeping track of operations performed on tensors. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
        "\n",
        "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
        "```python\n",
        "x = torch.zeros(1, requires_grad=True)\n",
        ">>> with torch.no_grad():\n",
        "...     y = x * 2\n",
        ">>> y.requires_grad\n",
        "False\n",
        "```\n",
        "\n",
        "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
        "\n",
        "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:52.867509Z",
          "start_time": "2021-05-26T22:26:52.860629Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcK-9mz2blU8",
        "outputId": "9bb97f00-acc4-4e62-d529-7019d419b028"
      },
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.9084,  0.0693],\n",
            "        [ 2.3417, -0.9669]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:53.383436Z",
          "start_time": "2021-05-26T22:26:53.375536Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hgYD_NeblU9",
        "outputId": "35d17300-78fa-4e91-fc1d-600dcc16be18"
      },
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[8.2513e-01, 4.8009e-03],\n",
            "        [5.4834e+00, 9.3494e-01]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqUHexRMblU_"
      },
      "source": [
        "Below we can see the operation that created `y`, a power operation `PowBackward0`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:53.870654Z",
          "start_time": "2021-05-26T22:26:53.867424Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyT5QpD8blU_",
        "outputId": "46b23887-ce0e-4238-87c6-7da7296fbe12"
      },
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PowBackward0 object at 0x7fcc91d04790>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7EUoyJjblVA"
      },
      "source": [
        "The autgrad module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:54.831912Z",
          "start_time": "2021-05-26T22:26:54.824631Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PQZoI8WblVB",
        "outputId": "90abdbeb-a0dd-455c-9dd9-8b0b33de10fd"
      },
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.8121, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42jBIsbhblVX"
      },
      "source": [
        "You can check the gradients for `x` and `y` but they are empty currently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:55.546143Z",
          "start_time": "2021-05-26T22:26:55.541213Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wVyYlmiblVZ",
        "outputId": "d5ed9e88-74b2-4149-df4f-eb0e72c956c0"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjh-PPKGblVZ"
      },
      "source": [
        "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:56.607560Z",
          "start_time": "2021-05-26T22:26:56.594993Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rNw8uEjblVa",
        "outputId": "25a77565-644d-4631-e05e-2892dac1d1d3"
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.4542,  0.0346],\n",
            "        [ 1.1708, -0.4835]])\n",
            "tensor([[-0.4542,  0.0346],\n",
            "        [ 1.1708, -0.4835]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnE6No7rblVb"
      },
      "source": [
        "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the weights with respect to the cost. With PyTorch, we run data forward through the network to calculate the cost, then, go backwards to calculate the gradients with respect to the cost. Once we have the gradients we can make a gradient descent step. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRme2iv_blVb"
      },
      "source": [
        "I'll build a network with `nn.Sequential` here. Only difference from the last part is I'm not actually using softmax on the output, but instead just using the raw output from the last layer. This is because the output from softmax is a probability distribution. Often, the output will have values really close to zero or really close to one. Due to [inaccuracies with representing numbers as floating points](https://docs.python.org/3/tutorial/floatingpoint.html), computations with a softmax output can lose accuracy and become unstable. To get around this, we'll use the raw output, called the **logits**, to calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:56.944759Z",
          "start_time": "2021-05-26T22:26:56.936939Z"
        },
        "id": "btR7gsbwblVc"
      },
      "source": [
        "# Hyperparameters for our network\n",
        "input_size   = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size  = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('logits', nn.Linear(hidden_sizes[1], output_size))]))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5soV9PublVd"
      },
      "source": [
        "## Training the network!\n",
        "\n",
        "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
        "\n",
        "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:57.317614Z",
          "start_time": "2021-05-26T22:26:57.313022Z"
        },
        "id": "Vnz1TuXYblVe"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhdxWOGdblVf"
      },
      "source": [
        "First, let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
        "\n",
        "* Make a forward pass through the network to get the logits \n",
        "* Use the logits to calculate the loss\n",
        "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
        "* Take a step with the optimizer to update the weights\n",
        "\n",
        "Below I'll go through one training step and print out the weights and gradients so you can see how it changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:27:07.408433Z",
          "start_time": "2021-05-26T22:27:07.373358Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_XSsxizblVg",
        "outputId": "e3ca9b51-2cdd-4558-980b-4cdd5c854bd4"
      },
      "source": [
        "print('Initial weights - ', model.fc1.weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(16, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model.forward(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model.fc1.weight.grad)\n",
        "optimizer.step()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0163,  0.0356,  0.0086,  ...,  0.0125, -0.0271, -0.0273],\n",
            "        [-0.0163,  0.0202, -0.0135,  ..., -0.0226,  0.0132,  0.0139],\n",
            "        [ 0.0056, -0.0139, -0.0338,  ..., -0.0345, -0.0020,  0.0038],\n",
            "        ...,\n",
            "        [-0.0066, -0.0108, -0.0068,  ..., -0.0268,  0.0067,  0.0044],\n",
            "        [-0.0276,  0.0029,  0.0002,  ..., -0.0177, -0.0102, -0.0054],\n",
            "        [ 0.0279, -0.0253,  0.0230,  ...,  0.0094,  0.0296,  0.0043]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0030, -0.0030, -0.0030,  ..., -0.0030, -0.0030, -0.0030],\n",
            "        ...,\n",
            "        [-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021],\n",
            "        [-0.0050, -0.0050, -0.0050,  ..., -0.0050, -0.0050, -0.0050],\n",
            "        [ 0.0028,  0.0028,  0.0028,  ...,  0.0028,  0.0028,  0.0028]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:27:07.915247Z",
          "start_time": "2021-05-26T22:27:07.908155Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m49USheFblVg",
        "outputId": "5ee75446-dc46-4c3e-ddaa-236bafd65bd0"
      },
      "source": [
        "print('Updated weights - ', model.fc1.weight)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0163,  0.0356,  0.0086,  ...,  0.0125, -0.0272, -0.0273],\n",
            "        [-0.0163,  0.0202, -0.0135,  ..., -0.0226,  0.0132,  0.0139],\n",
            "        [ 0.0056, -0.0138, -0.0338,  ..., -0.0345, -0.0020,  0.0038],\n",
            "        ...,\n",
            "        [-0.0066, -0.0108, -0.0068,  ..., -0.0268,  0.0068,  0.0044],\n",
            "        [-0.0275,  0.0030,  0.0003,  ..., -0.0177, -0.0102, -0.0053],\n",
            "        [ 0.0279, -0.0254,  0.0230,  ...,  0.0094,  0.0295,  0.0043]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xnm69vEblVh"
      },
      "source": [
        "### Training for real\n",
        "\n",
        "Now we'll put this algorithm into a loop so we can go through all the images. This is fairly straightforward. We'll loop through the mini-batches in our dataset, pass the data through the network to calculate the losses, get the gradients, then run the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:27:08.816179Z",
          "start_time": "2021-05-26T22:27:08.812807Z"
        },
        "id": "LZIhuRUsblVi"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.003)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:27:36.083537Z",
          "start_time": "2021-05-26T22:27:09.280769Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQnXnobSblVj",
        "outputId": "c9d41be7-14b9-445e-f70d-1bd18c7176d5"
      },
      "source": [
        "epochs = 3\n",
        "print_every = 40\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    print(f\"Epoch: {e+1}/{epochs}\")\n",
        "\n",
        "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
        "\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images.resize_(images.size()[0], 784)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model.forward(images)   # 1) Forward pass\n",
        "        loss = criterion(output, labels) # 2) Compute loss\n",
        "        loss.backward()                  # 3) Backward pass\n",
        "        optimizer.step()                 # 4) Update model\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if i % print_every == 0:\n",
        "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
        "            running_loss = 0"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3\n",
            "\tIteration: 0\t Loss: 0.0578\n",
            "\tIteration: 40\t Loss: 2.3035\n",
            "\tIteration: 80\t Loss: 2.2860\n",
            "\tIteration: 120\t Loss: 2.2656\n",
            "\tIteration: 160\t Loss: 2.2378\n",
            "\tIteration: 200\t Loss: 2.2149\n",
            "\tIteration: 240\t Loss: 2.2063\n",
            "\tIteration: 280\t Loss: 2.1723\n",
            "\tIteration: 320\t Loss: 2.1539\n",
            "\tIteration: 360\t Loss: 2.1281\n",
            "\tIteration: 400\t Loss: 2.0709\n",
            "\tIteration: 440\t Loss: 2.0212\n",
            "\tIteration: 480\t Loss: 1.9900\n",
            "\tIteration: 520\t Loss: 1.9236\n",
            "\tIteration: 560\t Loss: 1.8959\n",
            "\tIteration: 600\t Loss: 1.8025\n",
            "\tIteration: 640\t Loss: 1.7605\n",
            "\tIteration: 680\t Loss: 1.6964\n",
            "\tIteration: 720\t Loss: 1.6258\n",
            "\tIteration: 760\t Loss: 1.5435\n",
            "\tIteration: 800\t Loss: 1.5099\n",
            "\tIteration: 840\t Loss: 1.4534\n",
            "\tIteration: 880\t Loss: 1.3429\n",
            "\tIteration: 920\t Loss: 1.2626\n",
            "\tIteration: 960\t Loss: 1.2500\n",
            "\tIteration: 1000\t Loss: 1.1732\n",
            "\tIteration: 1040\t Loss: 1.1065\n",
            "\tIteration: 1080\t Loss: 1.0579\n",
            "\tIteration: 1120\t Loss: 1.0389\n",
            "\tIteration: 1160\t Loss: 0.9738\n",
            "\tIteration: 1200\t Loss: 0.9374\n",
            "\tIteration: 1240\t Loss: 0.9818\n",
            "\tIteration: 1280\t Loss: 0.8870\n",
            "\tIteration: 1320\t Loss: 0.8851\n",
            "\tIteration: 1360\t Loss: 0.8236\n",
            "\tIteration: 1400\t Loss: 0.8410\n",
            "\tIteration: 1440\t Loss: 0.8005\n",
            "\tIteration: 1480\t Loss: 0.7564\n",
            "\tIteration: 1520\t Loss: 0.7800\n",
            "\tIteration: 1560\t Loss: 0.7432\n",
            "\tIteration: 1600\t Loss: 0.7026\n",
            "\tIteration: 1640\t Loss: 0.7512\n",
            "\tIteration: 1680\t Loss: 0.6500\n",
            "\tIteration: 1720\t Loss: 0.6958\n",
            "\tIteration: 1760\t Loss: 0.6285\n",
            "\tIteration: 1800\t Loss: 0.6093\n",
            "\tIteration: 1840\t Loss: 0.6334\n",
            "\tIteration: 1880\t Loss: 0.6428\n",
            "\tIteration: 1920\t Loss: 0.6278\n",
            "\tIteration: 1960\t Loss: 0.5850\n",
            "\tIteration: 2000\t Loss: 0.5380\n",
            "\tIteration: 2040\t Loss: 0.6005\n",
            "\tIteration: 2080\t Loss: 0.5543\n",
            "\tIteration: 2120\t Loss: 0.5733\n",
            "\tIteration: 2160\t Loss: 0.5232\n",
            "\tIteration: 2200\t Loss: 0.5362\n",
            "\tIteration: 2240\t Loss: 0.5911\n",
            "\tIteration: 2280\t Loss: 0.5589\n",
            "\tIteration: 2320\t Loss: 0.4921\n",
            "\tIteration: 2360\t Loss: 0.5330\n",
            "\tIteration: 2400\t Loss: 0.4987\n",
            "\tIteration: 2440\t Loss: 0.5427\n",
            "\tIteration: 2480\t Loss: 0.5056\n",
            "\tIteration: 2520\t Loss: 0.4639\n",
            "\tIteration: 2560\t Loss: 0.5030\n",
            "\tIteration: 2600\t Loss: 0.4629\n",
            "\tIteration: 2640\t Loss: 0.4967\n",
            "\tIteration: 2680\t Loss: 0.4843\n",
            "\tIteration: 2720\t Loss: 0.4656\n",
            "\tIteration: 2760\t Loss: 0.5000\n",
            "\tIteration: 2800\t Loss: 0.4752\n",
            "\tIteration: 2840\t Loss: 0.4889\n",
            "\tIteration: 2880\t Loss: 0.5324\n",
            "\tIteration: 2920\t Loss: 0.5122\n",
            "\tIteration: 2960\t Loss: 0.4492\n",
            "\tIteration: 3000\t Loss: 0.4178\n",
            "\tIteration: 3040\t Loss: 0.3943\n",
            "\tIteration: 3080\t Loss: 0.4537\n",
            "\tIteration: 3120\t Loss: 0.4863\n",
            "\tIteration: 3160\t Loss: 0.4595\n",
            "\tIteration: 3200\t Loss: 0.4720\n",
            "\tIteration: 3240\t Loss: 0.4165\n",
            "\tIteration: 3280\t Loss: 0.4128\n",
            "\tIteration: 3320\t Loss: 0.4095\n",
            "\tIteration: 3360\t Loss: 0.4489\n",
            "\tIteration: 3400\t Loss: 0.4650\n",
            "\tIteration: 3440\t Loss: 0.4873\n",
            "\tIteration: 3480\t Loss: 0.4643\n",
            "\tIteration: 3520\t Loss: 0.4307\n",
            "\tIteration: 3560\t Loss: 0.4139\n",
            "\tIteration: 3600\t Loss: 0.5075\n",
            "\tIteration: 3640\t Loss: 0.3708\n",
            "\tIteration: 3680\t Loss: 0.4720\n",
            "\tIteration: 3720\t Loss: 0.5240\n",
            "Epoch: 2/3\n",
            "\tIteration: 0\t Loss: 0.0129\n",
            "\tIteration: 40\t Loss: 0.3927\n",
            "\tIteration: 80\t Loss: 0.4344\n",
            "\tIteration: 120\t Loss: 0.3875\n",
            "\tIteration: 160\t Loss: 0.4451\n",
            "\tIteration: 200\t Loss: 0.4133\n",
            "\tIteration: 240\t Loss: 0.4208\n",
            "\tIteration: 280\t Loss: 0.3926\n",
            "\tIteration: 320\t Loss: 0.3904\n",
            "\tIteration: 360\t Loss: 0.4244\n",
            "\tIteration: 400\t Loss: 0.4370\n",
            "\tIteration: 440\t Loss: 0.3709\n",
            "\tIteration: 480\t Loss: 0.4112\n",
            "\tIteration: 520\t Loss: 0.3865\n",
            "\tIteration: 560\t Loss: 0.3510\n",
            "\tIteration: 600\t Loss: 0.3461\n",
            "\tIteration: 640\t Loss: 0.4096\n",
            "\tIteration: 680\t Loss: 0.3801\n",
            "\tIteration: 720\t Loss: 0.3361\n",
            "\tIteration: 760\t Loss: 0.3649\n",
            "\tIteration: 800\t Loss: 0.3891\n",
            "\tIteration: 840\t Loss: 0.3892\n",
            "\tIteration: 880\t Loss: 0.4042\n",
            "\tIteration: 920\t Loss: 0.4134\n",
            "\tIteration: 960\t Loss: 0.4323\n",
            "\tIteration: 1000\t Loss: 0.4142\n",
            "\tIteration: 1040\t Loss: 0.3898\n",
            "\tIteration: 1080\t Loss: 0.3908\n",
            "\tIteration: 1120\t Loss: 0.3338\n",
            "\tIteration: 1160\t Loss: 0.3146\n",
            "\tIteration: 1200\t Loss: 0.3172\n",
            "\tIteration: 1240\t Loss: 0.3041\n",
            "\tIteration: 1280\t Loss: 0.3159\n",
            "\tIteration: 1320\t Loss: 0.3133\n",
            "\tIteration: 1360\t Loss: 0.3253\n",
            "\tIteration: 1400\t Loss: 0.3605\n",
            "\tIteration: 1440\t Loss: 0.3600\n",
            "\tIteration: 1480\t Loss: 0.3383\n",
            "\tIteration: 1520\t Loss: 0.3428\n",
            "\tIteration: 1560\t Loss: 0.3593\n",
            "\tIteration: 1600\t Loss: 0.3231\n",
            "\tIteration: 1640\t Loss: 0.3793\n",
            "\tIteration: 1680\t Loss: 0.4788\n",
            "\tIteration: 1720\t Loss: 0.3596\n",
            "\tIteration: 1760\t Loss: 0.3565\n",
            "\tIteration: 1800\t Loss: 0.3666\n",
            "\tIteration: 1840\t Loss: 0.3189\n",
            "\tIteration: 1880\t Loss: 0.3399\n",
            "\tIteration: 1920\t Loss: 0.4281\n",
            "\tIteration: 1960\t Loss: 0.3625\n",
            "\tIteration: 2000\t Loss: 0.3329\n",
            "\tIteration: 2040\t Loss: 0.3475\n",
            "\tIteration: 2080\t Loss: 0.3215\n",
            "\tIteration: 2120\t Loss: 0.3574\n",
            "\tIteration: 2160\t Loss: 0.3040\n",
            "\tIteration: 2200\t Loss: 0.3614\n",
            "\tIteration: 2240\t Loss: 0.4345\n",
            "\tIteration: 2280\t Loss: 0.3587\n",
            "\tIteration: 2320\t Loss: 0.3398\n",
            "\tIteration: 2360\t Loss: 0.3699\n",
            "\tIteration: 2400\t Loss: 0.3789\n",
            "\tIteration: 2440\t Loss: 0.3078\n",
            "\tIteration: 2480\t Loss: 0.3094\n",
            "\tIteration: 2520\t Loss: 0.2853\n",
            "\tIteration: 2560\t Loss: 0.3469\n",
            "\tIteration: 2600\t Loss: 0.3538\n",
            "\tIteration: 2640\t Loss: 0.3645\n",
            "\tIteration: 2680\t Loss: 0.3320\n",
            "\tIteration: 2720\t Loss: 0.3166\n",
            "\tIteration: 2760\t Loss: 0.3236\n",
            "\tIteration: 2800\t Loss: 0.3333\n",
            "\tIteration: 2840\t Loss: 0.4187\n",
            "\tIteration: 2880\t Loss: 0.3180\n",
            "\tIteration: 2920\t Loss: 0.3169\n",
            "\tIteration: 2960\t Loss: 0.2872\n",
            "\tIteration: 3000\t Loss: 0.3236\n",
            "\tIteration: 3040\t Loss: 0.3415\n",
            "\tIteration: 3080\t Loss: 0.3583\n",
            "\tIteration: 3120\t Loss: 0.3032\n",
            "\tIteration: 3160\t Loss: 0.3821\n",
            "\tIteration: 3200\t Loss: 0.3128\n",
            "\tIteration: 3240\t Loss: 0.3686\n",
            "\tIteration: 3280\t Loss: 0.3956\n",
            "\tIteration: 3320\t Loss: 0.3393\n",
            "\tIteration: 3360\t Loss: 0.3468\n",
            "\tIteration: 3400\t Loss: 0.3878\n",
            "\tIteration: 3440\t Loss: 0.3755\n",
            "\tIteration: 3480\t Loss: 0.3537\n",
            "\tIteration: 3520\t Loss: 0.2995\n",
            "\tIteration: 3560\t Loss: 0.3619\n",
            "\tIteration: 3600\t Loss: 0.2790\n",
            "\tIteration: 3640\t Loss: 0.3479\n",
            "\tIteration: 3680\t Loss: 0.3427\n",
            "\tIteration: 3720\t Loss: 0.2719\n",
            "Epoch: 3/3\n",
            "\tIteration: 0\t Loss: 0.0030\n",
            "\tIteration: 40\t Loss: 0.3176\n",
            "\tIteration: 80\t Loss: 0.3093\n",
            "\tIteration: 120\t Loss: 0.3377\n",
            "\tIteration: 160\t Loss: 0.3587\n",
            "\tIteration: 200\t Loss: 0.2834\n",
            "\tIteration: 240\t Loss: 0.3174\n",
            "\tIteration: 280\t Loss: 0.3352\n",
            "\tIteration: 320\t Loss: 0.3685\n",
            "\tIteration: 360\t Loss: 0.3401\n",
            "\tIteration: 400\t Loss: 0.3378\n",
            "\tIteration: 440\t Loss: 0.3494\n",
            "\tIteration: 480\t Loss: 0.3708\n",
            "\tIteration: 520\t Loss: 0.2675\n",
            "\tIteration: 560\t Loss: 0.2845\n",
            "\tIteration: 600\t Loss: 0.2787\n",
            "\tIteration: 640\t Loss: 0.2866\n",
            "\tIteration: 680\t Loss: 0.3654\n",
            "\tIteration: 720\t Loss: 0.3356\n",
            "\tIteration: 760\t Loss: 0.3429\n",
            "\tIteration: 800\t Loss: 0.3738\n",
            "\tIteration: 840\t Loss: 0.2760\n",
            "\tIteration: 880\t Loss: 0.2759\n",
            "\tIteration: 920\t Loss: 0.3817\n",
            "\tIteration: 960\t Loss: 0.3421\n",
            "\tIteration: 1000\t Loss: 0.2983\n",
            "\tIteration: 1040\t Loss: 0.2831\n",
            "\tIteration: 1080\t Loss: 0.3065\n",
            "\tIteration: 1120\t Loss: 0.3408\n",
            "\tIteration: 1160\t Loss: 0.2567\n",
            "\tIteration: 1200\t Loss: 0.3219\n",
            "\tIteration: 1240\t Loss: 0.2775\n",
            "\tIteration: 1280\t Loss: 0.3180\n",
            "\tIteration: 1320\t Loss: 0.3280\n",
            "\tIteration: 1360\t Loss: 0.3219\n",
            "\tIteration: 1400\t Loss: 0.3200\n",
            "\tIteration: 1440\t Loss: 0.2815\n",
            "\tIteration: 1480\t Loss: 0.3391\n",
            "\tIteration: 1520\t Loss: 0.2773\n",
            "\tIteration: 1560\t Loss: 0.3333\n",
            "\tIteration: 1600\t Loss: 0.3414\n",
            "\tIteration: 1640\t Loss: 0.2880\n",
            "\tIteration: 1680\t Loss: 0.3301\n",
            "\tIteration: 1720\t Loss: 0.3215\n",
            "\tIteration: 1760\t Loss: 0.2881\n",
            "\tIteration: 1800\t Loss: 0.2675\n",
            "\tIteration: 1840\t Loss: 0.2839\n",
            "\tIteration: 1880\t Loss: 0.2531\n",
            "\tIteration: 1920\t Loss: 0.2899\n",
            "\tIteration: 1960\t Loss: 0.3233\n",
            "\tIteration: 2000\t Loss: 0.2888\n",
            "\tIteration: 2040\t Loss: 0.2908\n",
            "\tIteration: 2080\t Loss: 0.2636\n",
            "\tIteration: 2120\t Loss: 0.3435\n",
            "\tIteration: 2160\t Loss: 0.2983\n",
            "\tIteration: 2200\t Loss: 0.2823\n",
            "\tIteration: 2240\t Loss: 0.2344\n",
            "\tIteration: 2280\t Loss: 0.2627\n",
            "\tIteration: 2320\t Loss: 0.2912\n",
            "\tIteration: 2360\t Loss: 0.3168\n",
            "\tIteration: 2400\t Loss: 0.3128\n",
            "\tIteration: 2440\t Loss: 0.2990\n",
            "\tIteration: 2480\t Loss: 0.3078\n",
            "\tIteration: 2520\t Loss: 0.2272\n",
            "\tIteration: 2560\t Loss: 0.3231\n",
            "\tIteration: 2600\t Loss: 0.3049\n",
            "\tIteration: 2640\t Loss: 0.3320\n",
            "\tIteration: 2680\t Loss: 0.2992\n",
            "\tIteration: 2720\t Loss: 0.3293\n",
            "\tIteration: 2760\t Loss: 0.3049\n",
            "\tIteration: 2800\t Loss: 0.3269\n",
            "\tIteration: 2840\t Loss: 0.2824\n",
            "\tIteration: 2880\t Loss: 0.3319\n",
            "\tIteration: 2920\t Loss: 0.2789\n",
            "\tIteration: 2960\t Loss: 0.2763\n",
            "\tIteration: 3000\t Loss: 0.3032\n",
            "\tIteration: 3040\t Loss: 0.2530\n",
            "\tIteration: 3080\t Loss: 0.2902\n",
            "\tIteration: 3120\t Loss: 0.3291\n",
            "\tIteration: 3160\t Loss: 0.3174\n",
            "\tIteration: 3200\t Loss: 0.2822\n",
            "\tIteration: 3240\t Loss: 0.2849\n",
            "\tIteration: 3280\t Loss: 0.2478\n",
            "\tIteration: 3320\t Loss: 0.3450\n",
            "\tIteration: 3360\t Loss: 0.3261\n",
            "\tIteration: 3400\t Loss: 0.2945\n",
            "\tIteration: 3440\t Loss: 0.2730\n",
            "\tIteration: 3480\t Loss: 0.3009\n",
            "\tIteration: 3520\t Loss: 0.2940\n",
            "\tIteration: 3560\t Loss: 0.3325\n",
            "\tIteration: 3600\t Loss: 0.2920\n",
            "\tIteration: 3640\t Loss: 0.2459\n",
            "\tIteration: 3680\t Loss: 0.2955\n",
            "\tIteration: 3720\t Loss: 0.2527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogP4MX8dblVk"
      },
      "source": [
        "With the network trained, we can check out it's predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:30:00.206666Z",
          "start_time": "2021-05-26T22:29:59.954325Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "moc2GdhYblVk",
        "outputId": "e3158cf3-eb56-4483-d9f2-fcd238d6fda2"
      },
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logits = model.forward(img)\n",
        "\n",
        "# Output of the network are logits, need to take softmax for probabilities\n",
        "ps = F.softmax(logits, dim=1)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 349,
              "height": 195
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAViqSloblVl"
      },
      "source": [
        "Now our network is brilliant. It can accurately predict the digits in our images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTg-asP0blVm"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "    <h2 align=\"center\" style=\"color:#01ff84\">EMNIST Classification: Exercise</h2>\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDGXSELyblVm"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 1:</h3>\n",
        "  <p>Now it's your turn to build a simple network, use any method I've covered so far. In the next notebook, you'll learn how to train a network so it can make good predictions.</p>\n",
        "  <p>Build a network to classify the MNIST images with 3 hidden layers. Use 16 units in the first hidden layer, 32 units in the second layer, and 8 units in the third layer. Each hidden layer should have a ReLU activation function, and use softmax on the output layer.</p>\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDGnr8XlblVn"
      },
      "source": [
        "## TODO: Your network here\n",
        "# Hyperparameters for our network\n",
        "input_size   = 784\n",
        "hidden_sizes = [16, 8, 8]\n",
        "output_size  = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[2])),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('logits', nn.Linear(hidden_sizes[1], output_size))]))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "VRDvy6-MblVo",
        "outputId": "225729c9-3623-4251-8b55-fcf7abf38ee0"
      },
      "source": [
        "# Run this cell with your model to make sure it works\n",
        "# Forward pass through the network and display output\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0,:])\n",
        "view_classify(images[0].view(1, 28, 28), ps)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 349,
              "height": 195
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMkelhplblVo"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 2:</h3>\n",
        "  <p>Train your network implementing the Pytorch training loop and <strong style=\"color:#01ff84\">after each epoch, use the model for predicting the test (validation) MNIST data.</strong></p>\n",
        "  <p>Note: If your model does not fit with the final softmax layer, you can remove this layer.</p>\n",
        "  <p>Hint: <a href=\"https://discuss.pytorch.org/t/training-loop-checking-validation-accuracy/78399\">Training loop checking validation accuracy\n",
        "</a></p>\n",
        "  <p>Research about <code>model.train()</code>, <code>model.eval()</code> and <code>with torch.no_grad()</code> in Pytorch.\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOK2S1xT8z5h"
      },
      "source": [
        "epochs = 10\n",
        "print_every = 40\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    print(f\"Epoch: {e+1}/{epochs}\")\n",
        "\n",
        "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
        "\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images.resize_(images.size()[0], 784)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model.forward(images)   # 1) Forward pass\n",
        "        loss = criterion(output, labels) # 2) Compute loss\n",
        "        loss.backward()                  # 3) Backward pass\n",
        "        optimizer.step()                 # 4) Update model\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if i % print_every == 0:\n",
        "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
        "            running_loss = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "aEFlqqLhblVp",
        "outputId": "3616906b-80c7-4de4-baed-46cb07823b3d"
      },
      "source": [
        "## TODO: Your training loop here\n",
        "epochs = 3\n",
        "print_every = 40\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    print(f\"Epoch: {e+1}/{epochs}\")\n",
        "\n",
        "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
        "      \n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  model.train()\n",
        "  model.eval()\n",
        "  torch.no_grad() "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-9fb52d463f1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## TODO: Your training loop here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G88db6DblVq"
      },
      "source": [
        "# Run this cell with your model to make sure it works and predicts well for the validation data\n",
        "images, labels = next(iter(testloader))\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0,:])\n",
        "view_classify(images[0].view(1, 28, 28), ps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKGc1HwrblVq"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 3:</h3>\n",
        "  <p>Write the code for adding <strong style=\"color:#01ff84\">Early Stopping with patience = 2</strong> to the training loop from scratch.</p>\n",
        "  <p><strong style=\"color:#01ff84\">Hint:</strong> Monitor the Validation loss every epoch, and if in 2 epochs, the validation loss does not improve, stop the training loop with <code>break</code>.</p>\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL1Rk0nLblVq"
      },
      "source": [
        "## TODO: Your training loop here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dVzmqTDblVq"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "  <h3 style=\"color:#01ff84; margin-top:4px\">Optional:</h3>\n",
        "  <p>Don't you want to use MNIST? Try EMNIST instead! Maybe using the first 10 letters of the alphabet!</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:35:26.981584Z",
          "start_time": "2021-05-26T22:35:26.954522Z"
        },
        "id": "CHNWuEriblVr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:50:57.571260Z",
          "start_time": "2021-05-26T22:50:57.322172Z"
        },
        "id": "nndAhNZSblVr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_jp1EEmblVs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:51:03.118421Z",
          "start_time": "2021-05-26T22:51:02.978678Z"
        },
        "id": "w-jufaeRblVu"
      },
      "source": [
        "plt.imshow(images[5].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:51:06.653639Z",
          "start_time": "2021-05-26T22:51:06.647991Z"
        },
        "id": "inZORmT_blVu"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHCFq-F4blVu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}